# ⛩️

## 参考

🛣️ https://roadmap.sh/mlops
📚
* Huyen designing ml systems https://www.amazon.com/dp/1098107969
* https://www.amazon.com/Machine-Learning-System-Design-Interview/dp/1736049127
* https://www.amazon.com/Generative-AI-System-Design-Interview/dp/1736049143
* https://www.amazon.com/dp/1098149246

## 进步

* _25_: try new providers (Grok, Gemini)
* _24_: ChatGPT (regex and Polars, then incorporate research) Claude (switch after GPT outage)
* _23_: few random queries

* web search https://simonwillison.net/2025/May/7/anthropic-api-search/

DEEP RESEARCH ETC.
* https://news.ycombinator.com/item?id=43752262
> Contrast this to everywhere I see people ravenously using new tools, like Cursor for coding, OpenAI Operator, or even fairly ‘basic’ uses like lawyers using NotebookLM to summarize case documents in a way they can listen to in the car. https://registerspill.thorstenball.com/p/joy-and-curiosity-33
labs https://blog.omega-prime.co.uk/2025/04/11/ai-lab-business/
> I strongly feel that this is an insult to life itself. I am utterly disgusted. https://carly.substack.com/p/everything-is-ghibli
Simon Prince book https://news.ycombinator.com/item?id=43121059
https://openai.com/index/introducing-deep-research/ https://x.com/mckaywrigley/status/1886215847481623030 https://x.com/felipe_millon/status/1886205433469178191 https://thezvi.substack.com/p/were-in-deep-research https://x.com/sayashk/status/1887275315824660584 https://www.fromthenew.world/p/openai-deep-research-explains-itself https://x.com/patrickc/status/1888312657146757315 https://stratechery.com/2025/deep-research-and-knowledge-value/
> OpenAI made a big splash launching ‘Deep Research’, an agent-ish tool within the $200 Pro plan that uses a version of the computationally-intensive (and expensive) o3 ‘reasoning’ model to write research reports, coming back in a few hours when it’s done. As for most generative AI demos, very cool if you have that use case, but you have to be careful - I spotted some large mistakes even in one of the examples on the marketing page (in a field I know a lot about). I always used to compare machine learning to ‘infinite interns’ and now you can ask an AI intern to write a long report about something - but you’ll need to check every line of it, and it probably won’t say anything surprising (since surprising is a divergence from the data). - Ben Evans 25.02.11
https://news.ycombinator.com/item?id=43236184 https://simonwillison.net/2025/Mar/4/deepsearch-deepresearch/
* search-enabled https://simonwillison.net/2025/Apr/21/ai-assisted-search/
> But there’s one very significant difference: these models can run searches as part of the chain-of-thought reasoning process they use before producing their final answer.
> The user-facing Google Gemini app can search too, but it doesn’t show me what it’s searching for. As a result, I just don’t trust it.
> It churned away thinking for 21 seconds, ran a bunch of searches, figured out the new library (which existed way outside of its training cut-off date), found the upgrade instructions and produced a new version of my code that worked perfectly.
> This also means that a bunch of the potential dark futures we’ve been predicting for the last couple of years are a whole lot more likely to become true. Why visit websites if you can get your answers directly from the chatbot instead?

# 🌐 CONTEXT

* memory https://help.openai.com/en/articles/10303002-how-does-memory-use-past-conversations

## import

🗄️
* `eng/doc.md`
* `linguistics.md` determinism
* `media.md` print culture

ARCHITECTURE
* you have to write more https://simonwillison.net/2025/May/20/after-months-of-coding-with-llms/
* https://bsky.app/profile/emollick.bsky.social/post/3lp5afidgvc2a
> https://news.ycombinator.com/item?id=42095434 there's a fair amount of pushback as well. i align with the first comment to this guy. decent amount of pushback seems like: "im a real man, my editor is emacs, i have strong opinions about c99 vs. rust, LLMs are for wimps who write $DYNAMICALLY_TYPED_LANGUAGE_HERE" + people that are bad at writing prompts. essentially, LLMs reward the type of person who could write a good question on Stack Overflow or otherwise teaches them how to do so (if they are willing to learn) https://stackoverflow.com/help/mcve - to Josh/Kurt 24.11.15
* https://news.ycombinator.com/item?id=42336553
* ADRs / Stack Overflow won https://harper.blog/2025/04/17/an-llm-codegen-heros-journey/ https://registerspill.thorstenball.com/p/joy-and-curiosity-36 https://mathstodon.xyz/@tao/110601051375142142
> While we’ve always valued strong communicators on tech teams for documentation and collaboration, it’s doubly important now. Not only do you need to communicate with humans, you need to write clear, precise instructions for AI. Being able to craft effective prompts is becoming as vital as writing good code.
> Suddenly you find yourself building out very robust specs, PRDs, and to-do docs.
* https://steve-yegge.blogspot.com/2008/09/programmings-dirtiest-little-secret.html
> For starters, non-typists are almost invisible. They don't leave a footprint in our online community...design involves communicating with other people, and design involves a persistent record of the decision tree.
>"And as for this non-college bullshit I got two words for that: learn to fuckin' type."

VIBE CODING
* https://simonwillison.net/2025/May/1/not-vibe-coding/
* good for MVPs https://news.ycombinator.com/item?id=43576813
* https://simonwillison.net/2025/Mar/6/vibe-coding/ https://simonwillison.net/2025/Mar/19/vibe-coding/ https://www.youtube.com/watch?v=YWwS911iLhg

10x
* https://simonwillison.net/2024/Oct/21/claude-artifacts/
* supercharged smart young people https://www.youtube.com/watch?v=OmiwV8kUz2E https://www.bitecode.dev/p/what-if-ai-eventually-make-programmers
* https://marginalrevolution.com/marginalrevolution/2024/12/why-you-should-be-talking-with-gpt-about-philosophy.html
> this sounds hyperbolic, but i think AI is going to be akin to the dawn of relational databases in the 80s when it comes to the software industry. re: orgs.  take databases: "no you dont need all those people punching up figures. you can replace all your accountants and secretaries with cobol!". -> do we have more or less jobs centered around the production/maintenance/whatever of business data in 2024 than we did in 1974? it would seem to me a great deal more. dunno if this will hold for number of devs, but feel >=50% that there will be a fuck ton more code written in 5 years than today. bigger economy = longer tail
> The amount of money flowing through capitalism would astound you. The number and variety of firms participating in the economy would astound you. We don't see most of it every day for the same reason abstractions protect us from having to care about metallurgy while programming. - McKenzie https://twitter.com/patio11/status/936629780719419392
> AI as a mechanical arm - you still need to know how to hit the ball, but once you do, it'll go a lot further. https://registerspill.thorstenball.com/p/joy-and-curiosity-36

---

* garbage in garbage out
> OpenAI published a very long guide to ‘prompt engineering’ for GPT-4.1. I find this kind of stuff unintentionally hilarious: if your thesis is that these models are replacing software, why do I need to memorise incantations and learn what JSON means to get the best results? All of this should be abstracted away. - Ben Evans 25.05.20
* https://simonwillison.net/2025/Apr/20/ethan-mollick/
* https://news.ycombinator.com/item?id=43752492
* teaching people how to ask better questions https://paulgraham.com/writes.html
> PG might be right for most people but I estimate that LLMs will actually make their users *better* at writing clearly. Will take the Stack Overflow ethos to a wider audience. https://stackoverflow.com/help/how-to-ask
* Stack Overflow won in losing https://x.com/Altimor/status/1853893158368928124
* Cursor files https://getstream.io/blog/cursor-ai-large-projects/
* `claude.txt`/`claude.md` = lol "have docs" as an *idea* https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials?q=CLAUDE.md+#create-an-effective-claude-md-file
* autocomplete is not the reason https://www.arguingwithalgorithms.com/posts/cursor-review.html https://ghuntley.com/stdlib/
> learn how to fucking type (and how to write https://news.ycombinator.com/item?id=43739400)
> Harper on An LLM Codegen Hero's Journey: "Writing skills have become critical. While we’ve always valued strong communicators on tech teams for documentation and collaboration, it’s doubly important now." One hundred thousand percent correct, I’d say. This week I gave a little talk on how to write better prompts when using Amp and I had a slide in there that said: what makes a good prompt are the same things that make a good ticket and good bug report
> have standards 💡️ use AI to write docs and understand the entire architecture of the system https://www.driver.ai/
* `.cursor/rules`/`.cursorrules` https://www.nickcraux.com/blog/cursor-tip https://news.ycombinator.com/item?id=43341506 https://docs.cursor.com/context/rules-for-ai https://news.ycombinator.com/item?id=43658923
> Eng leadership at my place are pushing Cursor pretty hard. It's great for banging out small tickets and improving the product incrementally kaizen-style, but it falls down with anything heavy. I think it's weakening junior engineers' reasoning and coding abilities as they become reliant on it without having lived for long, or at all, in the before times. I think may be doing the same to me too...As with so many products, it's cheap to start with, you become dependent on it, then one day it's not cheap and you're fucked.
* what I use it for (beyond code): summarization, taxonomization, big picture, learning new concepts (regression, dimensional analysis) https://github.com/zachvalenta/apple-models-data-analysis
> that little repo took me ~30 minutes total work, spanning initial idea to completion. that * ideas in a day * days in a year has been a massive delta for me. ++ I feel like my ability to use AI tooling well growing exponentially. diff btw today vs. a month ago night and day.
* misunderstanding https://www.youtube.com/watch?v=dkV01hBdhZE https://registerspill.thorstenball.com/p/they-all-use-it https://news.ycombinator.com/item?id=41930767
makes mistakes all the time but that's why we're here! re: `direnv` https://chatgpt.com/c/673f8c16-e090-8004-bdc8-564bbfeb33d5
> The crux of my raging hatred is not that I hate LLMs or the generative AI craze. I had my fun with Copilot before I decided that it was making me stupider - it's impressive, but not actually suitable for anything more than churning out boilerplate. Nothing wrong with that, but it did not end up being the crazy productivity booster that I thought it would be, because programming is designing and these tools aren't good enough (yet) to assist me with this seriously. https://ludic.mataroa.blog/blog/i-will-fucking-piledrive-you-if-you-mention-ai-again/
> LLMs are good at explaining code. Give it code in a language you don't understand and it will explain it with 90% accuracy. https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html#simon-willison-keynote
https://www.youtube.com/watch?v=ImNpR0O8nuA
https://marginalrevolution.com/marginalrevolution/2025/02/o1-pro.html
forcing people to think through things https://x.com/RealGeneKim/status/1853860996689064211
https://registerspill.thorstenball.com/p/surely-not-all-codes-worth-it https://registerspill.thorstenball.com/p/how-might-ai-change-programming
sketching https://simonwillison.net/2024/Dec/4/steve-yegge/
https://x.com/barbell_fi
https://simonwillison.net/2023/Dec/31/ai-in-2023/
https://simonwillison.net/2024/Dec/11/who-and-what-comprise-ai-skepticism/#atom-everything
https://simonwillison.net/2024/Dec/10/ethan-mollick/
* https://simonwillison.net/2025/Apr/7/john-carmack/
* https://news.ycombinator.com/item?id=42936346
```txt
I'm going to take a contrarian view and say it's actually a good UI, but it's all about how you approach it.
I just finished a small project where I used o3-mini and o3-mini-high to generate most of the code. I averaged around 200 lines of code an hour, including the business logic and unit tests. Total was around 2200 lines. So, not a big project, but not a throw away script. The code was perfectly fine for what we needed. This is the third time I've done this, and each time I get faster and better at it.
1. I find a "pair programming" mentality is key. I focus on the high-level code, and let the model focus on the lower level code. I code review all the code, and provide feedback. Blindly accepting the code is a terrible approach.
2. Generating unit tests is critical. After I like the gist of some code, I ask for some smoke tests. Again, peer review the code and adjust as needed.
3. Be liberal with starting a new chat: the models can get easily confused with longer context windows. If you start to see things go sideways, start over.
4. Give it code examples. Don't prompt with English only.
```
* https://www.thoughtworks.com/radar/techniques/observability-2-0 https://claude.ai/chat/6bcfcae0-6294-47ef-a3bf-588a7f178c0e
* https://crawshaw.io/blog/programming-with-llms
* https://x.com/robertghrist/status/1874105564051234951
> “When thinking about coding with LLMs, think of them as generators of templates. You say what code you need, and an LLM provides you with a template from a collection that most closely resembles the code you needed.” I’ve said something similar in different conversations these past few weeks and that I’ve begun thinking of LLMs-as-code-assistant more in the category of frameworks and generators than magic wands. https://registerspill.thorstenball.com/p/joy-and-curiosity-23
* https://simonwillison.net/2024/Dec/31/llms-in-2024/#knowledge-is-incredibly-unevenly-distributed https://simonwillison.net/2024/Dec/31/llms-in-2024/#synthetic-training-data-works-great

## agents

🔍 https://mychaelangelo.github.io/ai_agents_marketmap/
🗄️
* `clients.md` MCP
* `clients.md` in use

BYO
* Thorsten Ball https://ampcode.com/how-to-build-an-agent
* Stevens https://www.geoffreylitt.com/2025/04/12/how-i-made-a-useful-ai-assistant-with-one-sqlite-table-and-a-handful-of-cron-jobs https://simonwillison.net/2025/Apr/13/stevens/ https://simonwillison.net/2025/Apr/13/stevens/
* _Pocket_: https://news.ycombinator.com/item?id=43739456 https://github.com/The-Pocket/Tutorial-Codebase-Knowledge
* custom GPT via GPT Builder 📙 Selvaraj automate [7.5]

ATTEMPTS TO DEFINE https://www.anthropic.com/research/building-effective-agents
* = act in an environment https://simonwillison.net/2025/Jun/5/wrecking-its-environment-in-a-loop/
* = models used in a loop https://simonwillison.net/2025/May/22/tools-in-a-loop/
> Watching Windsurf take multiple actions on my behalf without my input is very inspirational. I’m dreaming of a world where Townie not only detects errors, but also automatically tries to fix them, possibly multiple times, possibly in parallel across different branches, without any human interaction. Here, of course, we’d be getting into territory mostly explored by the folks at Devin. For starters, we could feed back screenshots of the generated website back to the LLM. But soon you’d want to give the LLM access to a full web browser so it can itself poke around the app, like a human would, to see what features work and which ones don’t. Maybe then it’d even write some tests, also like a human would, to make sure things don’t break as it continues to iterate. I have a vague sense by the end of this year that you’ll be able to tell Townie to “make a fully realistic Hacker News Clone, with user accounts, nested comments, upvotes, downvotes” and it could iterate for potentially hours on your behalf. You could even go to bed and wake up with it done. https://blog.val.town/blog/fast-follow/
= can go out and use the internet https://x.com/rowancheung/status/1898093008601395380
> An agent is something that acts in an environment; it does something. https://simonwillison.net/2025/Mar/19/worms-and-dogs-and-countries/
* give it a dataset, it writes the paper https://www.oneusefulthing.org/p/almost-an-agent-what-gpts-can-do
* "can read|update my code" https://www.youtube.com/watch?v=zIejF3IGtWk

HISTORY https://blog.val.town/blog/fast-follow/
* function calling
* artifacts https://www.anthropic.com/news/claude-3-5-sonnet
* agentic

---

* https://www.youtube.com/watch?v=eHEHE2fpnWQ
* start using https://github.blog/news-insights/product-news/github-copilot-the-agent-awakens/
https://simonwillison.net/2025/Jan/11/agents/
https://simonwillison.net/2024/Dec/31/llms-in-2024/#-agents-still-haven-t-really-happened-yet
https://www.thoughtworks.com/radar/techniques/function-calling-with-llms
> They discuss "agentic systems" as a parent term, then define a distinction between "workflows" - systems where multiple LLMs are orchestrated together using pre-defined patterns - and "agents", where the LLMs "dynamically direct their own processes and tool usage". https://simonwillison.net/2024/Dec/20/building-effective-agents/
* as judge https://registerspill.thorstenball.com/p/joy-and-curiosity-20
* LLM controlling your browser?
https://ai.pydantic.dev/
https://www.thediff.co/archive/offshoring-and-ai-agents/
https://github.com/ishan0102/vimGPT
https://edwardbenson.com/2024/06/how-to-reason-about-agent-performance#user-content-fn-1
https://edwardbenson.com/2024/11/the-worlds-first-ai-street-hawker
https://edwardbenson.com/lollm
https://news.ycombinator.com/item?id=42299098
https://x.com/SullyOmarr/status/1864697992261062690/photo/1

## interchange (MCP)

🗄️
* `models.md` agent

---

https://www.youtube.com/watch?v=KmjhwRYBbok

MODEL CONTEXT PROTOCOL (MCP)
* protocol to allow clients (in this case, models) to use tools (e.g. here are the queries you can run against a database) https://www.youtube.com/watch?v=oX6IKXfcx78
* impl https://pypi.org/project/mcp/
* usage https://github.com/jasonjmcghee/claude-debugs-for-you
* _MCP (model context protocol)_: spec for comms btw hosted model and data to enable RAG https://news.ycombinator.com/item?id=42237424 https://glama.ai/blog/2024-11-25-model-context-protocol-quickstart
> Today, we're open-sourcing the Model Context Protocol (MCP), a new standard for connecting AI assistants to the systems where data lives, including content repositories, business tools, and development environments. Its aim is to help frontier models produce better, more relevant responses. https://www.anthropic.com/news/model-context-protocol
> But none of the examples seem to indicate what the protocol is, whether it's a RAG sort of thing, do I need to prompt, etc.
> From what I understand, "servers" are data sources that an LLM can query at will to answer questions, using this new protocol. They're connectors to external information that the LLM can process on the fly.
> The gist of it is: you have an llm application such as Claude desktop. You want to have it interact (read or write) with some system you have. MCP solves this.
> An attempt to create a standard protocol to plug tools to LLM app via the good ol' tools/function calling mechanism. It's not introducing new capabilities, just solving the NxM problem, hopefully leading to more tools being written. -> functional calling https://blog.val.town/blog/fast-follow/

* databases https://github.com/bytebase/dbhub
Browser MCP https://news.ycombinator.com/item?id=43613194
https://simonwillison.net/2025/Apr/18/mcp-run-python/
https://github.com/pydantic/pydantic-ai/tree/main/mcp-run-python
* https://news.ycombinator.com/item?id=43676771
* https://github.com/jlowin/fastmcp
> Put simply, MCP is a way for LLMs to more easily integrate with external tools. MCP Servers: Providers like Sentry, Slack, JIRA, Gmail, etc. set up adapters around their APIs that follow the MCP Protocol. https://read.highgrowthengineer.com/p/mcps-simply-explained
https://github.com/github/github-mcp-server
Postgres https://news.ycombinator.com/item?id=43520953
https://simonwillison.net/2025/Mar/25/playwright-mcp/
schemas https://simonwillison.net/2025/Feb/28/llm-schemas/
https://github.com/crmne/ruby_llm
https://registerspill.thorstenball.com/p/joy-and-curiosity-30 https://github.com/punkpeye/awesome-mcp-servers
https://github.com/simonw/llm/releases/tag/0.23
https://www.youtube.com/watch?v=oX6IKXfcx78

```python
import openai
openai.api_key = "your_openai_api_key"
messages = [ {"role": "user", "content": "Explain how to use Markdown to create tables."} ]
response = openai.ChatCompletion.create( model="gpt-4", messages=messages)
content = response.choices[0].message['content']
with open("response.md", "w") as f:
    f.write(content)
```

* export from GPT: navigate to data controls > export data
```python
import json
with open("conversations.json", "r") as f:
    data = json.load(f)
for conversation in data["conversations"]:
    filename = f"{conversation['title'].replace(' ', '_')}.md"
    with open(filename, "w") as md_file:
        md_file.write(f"# {conversation['title']}\n\n")
        for message in conversation["mapping"].values():
            role = message["message"]["author"]["role"]
            content = message["message"]["content"]["parts"][0]
            md_file.write(f"**{role.capitalize()}**:\n{content}\n\n")
```

> OpenAI now supports structured output, allowing developers to supply a JSON Schema, pydantic or Zod object to constrain model responses. https://www.thoughtworks.com/radar/techniques/structured-output-from-llms

https://simonwillison.net/2025/Jan/24/anthropics-new-citations-api/
https://news.ycombinator.com/item?id=42753302

* GPT code completions API https://www.youtube.com/watch?v=g9tIm50VO4g
* GPT as standard https://simonwillison.net/2024/Dec/22/openai-openapi/
* API spec
> ch works with any compatible chat completion API that has the same interface as ChatGPT https://github.com/dnmfarrell/ch
> Projects such as LocalAI offer a REST API that imitates the OpenAI API but can be used to run other models, including models that can be installed on your own machine. These can be added using the same configuration mechanism. https://llm.datasette.io/en/stable/other-models.html#openai-compatible-models
* Claude JSON export https://simonwillison.net/2024/Oct/21/claude-artifacts/ https://simonwillison.net/2024/Dec/31/llms-in-2024/#prompt-driven-app-generation-is-a-commodity-already
* _Amazon bedrock_: API for all models https://docs.aws.amazon.com/bedrock/latest/userguide/what-is-bedrock.html

---

FILE FMT
https://chatgpt.com/c/671bf6dc-3058-8004-8e67-fff34d61eb1a https://chatgpt.com/c/671ebbd6-c110-8004-a519-0f723970d64c
* streaming https://til.simonwillison.net/llms/streaming-llm-apis
* _JSON_: Superpower ChatGPT, Claude https://github.com/simonw/claude-to-sqlite https://simonw.substack.com/p/everything-i-built-with-claude-artifacts https://support.anthropic.com/en/articles/9450526-how-can-i-export-my-claude-ai-data
> you've more in Elia about JSON export
* _Markdown_: https://simonw.substack.com/p/video-scraping-using-google-gemini https://github.com/kardolus/chatgpt-cli?tab=readme-ov-file#markdown-rendering
> don't forget you should be able to parse JSON to Markdown as well
* _XML_: https://github.com/simonw/files-to-prompt

browser interaction https://news.ycombinator.com/item?id=42052432 https://news.ycombinator.com/item?id=42052432
> Claude from the browser https://news.ycombinator.com/item?id=42012412

## prompts

📙 https://www.manning.com/books/prompt-engineering-in-practice https://www.manning.com/books/prompt-engineering-in-action https://www.promptingguide.ai/
🗄️
* `dotfiles/ai/aider/conventions`
* `clients.md` context
*️ `work.md` industry > Stack Overflow
* `ur-repo` prompt workflow https://harper.blog/2025/02/16/my-llm-codegen-workflow-atm/ https://llmstxt.org/ https://svelte.dev/llms-small.txt https://simonwillison.net/2025/Mar/11/using-llms-for-code/ https://simonwillison.net/2025/Mar/11/using-llms-for-code/ claude.md https://docs.anthropic.com/en/docs/agents-and-tools/claude-code/tutorials

ZA
* ask it to try harder https://simonwillison.net/2025/Jan/3/asking-them-to-write-better-code/
* BYO your own characters https://news.ycombinator.com/item?id=42107113
* _zero/one/few shot_: how many examples you give https://www.promptingguide.ai/techniques/fewshot https://www.thoughtworks.com/radar/techniques/dynamic-few-shot-prompting

SEMANTICS
* _prompt_: question
* _completion_: answer 📙 Clinton obsolete gen AI
* _system message_: hidden instruction that defines the behavior/goals/tone of the model; aka system prompt https://chatgpt.com/c/67106e28-a6e0-8004-9ef0-dd2f3b1eb48b
> "You are a helpful assistant named Elia." https://github.com/charmbracelet/mods#custom-roles
* _chain of density_: prompting LLM to continually refine https://www.youtube.com/watch?v=9Ev208-Gc4c
```txt
🫀 human: Summarize this passage -> "The Roman Empire, one of the most influential civilizations, spanned centuries and contributed to law, architecture, and governance. Their legal system influenced modern law, and their roads facilitated trade and military movement."
🤖 AI: The Roman Empire significantly shaped law, architecture, and governance, with its legal system and roads having a lasting impact.
🫀 human: Condense further while keeping all key points.
🤖 AI: Rome’s legal system, architecture, and roads shaped civilization.
```
* _prompt injection_: getting model to do something its creators don't want https://simonwillison.net/2023/Dec/31/ai-in-2023/
> Simon coined the term prompt injection after SQL Injection. He believes that we are not seeing digital assistants, because no one knows how to build them securely. 99% effective isn't good enough. Never mix untrusted text with access to tools. https://katherinemichel.github.io/portfolio/pycon-us-2024-recap.html#simon-willison-keynote

---

https://x.com/david_perell/status/1897387371244478668
> Use AI as your secondary literature when you read — not just for quick answers, but as a thinking companion. As Tyler puts it, "I'll keep on asking the AI: 'What do you think of chapter two? What happened there? What are some puzzles?' It just gets me thinking... and I'm smarter about the thing in the final analysis."
> Hallucinations aren't the crisis everyone makes them out to be. No matter the source, if you're going to use a piece of information, you should double-check it. This is true for both books and AI.

## RAG

pairwise https://gwern.net/resorter Bradley-Terry https://en.wikipedia.org/wiki/Bradley%E2%80%93Terry_model

💡 core model enhanced by access to specific docs
🛠️ markitdown https://github.com/Goldziher/kreuzberg
🗄️
* `doc.md` notes
* `algos.md` search > bm25
📚
* Bratanic https://www.manning.com/books/knowledge-graph-enhanced-rag
* Farooq build LLM apps https://www.manning.com/books/build-llm-applications-from-scratch https://www.alldayta.com/#product-demo
* Kimothi https://www.manning.com/books/a-simple-guide-to-retrieval-augmented-generation

* https://github.com/oramasearch/orama
https://www.youtube.com/watch?v=hB7sGE0W8CI
https://github.com/gusye1234/nano-graphrag
with Databricks https://youtube.com/watch?v=p4qpIgj5Zjg
https://github.com/Cinnamon/kotaemon
https://entgo.io/blog/2025/02/12/rag-with-ent-atlas-pgvector/

HOWTO (LEARN BY BUILDING FOR DROR)
```txt
I'm still new to the space, so take with a grain of salt https://chatgpt.com/share/6756f806-27c4-8004-8768-b94f879a8b5e

* data prep: I have a good library in mind https://github.com/chonkie-ai/chonkie
* embeddings: would probably do with model aaS (GPT, Claude)
* vector db: I've been keeping tabs of the vector db ecosystem but that means ~20 links I haven't yet read and need to. Hopefully I can find either an embedded option or a good hosted service.
* training: assume we'd use transfer | reinforcement learning vs. getting into the weeds with adjusting the weights (finetuning, LoRA, PEFT) https://www.youtube.com/watch?v=55guW-DZVM0
```
* prompt
```txt
I want to build RAG for a book I'm writing so that I can learn more about the book (where is the structure weak? what connections *could* I make that I haven't already?). I want the RAG to act as some combination of an editor and a critic.
```
* completion
```txt
1. Data Preparation
Segment the Book: Split your manuscript into manageable chunks, such as chapters, sections, or paragraphs.
Create Metadata: Annotate each chunk with relevant metadata (e.g., chapter, themes, key ideas).
Embed Contextual Information: If you have earlier drafts, notes, or research material, include these as part of the corpus.
2. Knowledge Base Construction
Use embeddings to create a vectorized representation of each chunk, enabling semantic search. Libraries like OpenAI's embeddings, Hugging Face, or Sentence Transformers are excellent choices.
Organize a knowledge base (e.g., Pinecone, Weaviate, or FAISS) to allow fast and efficient retrieval.
3. RAG Architecture
Retrieval Component: Query your knowledge base for related chunks based on prompts.
Generation Component: Use a generative model fine-tuned on critique/editing tasks. Models like GPT-4 or fine-tuned open-source models can work well here.
4. Functionality
Structural Weakness Analysis: Prompt the system with questions like, “What parts of this argument lack support?” or “Where does the structure feel inconsistent?”
Connection Suggestions: Use prompts like, “What connections can be made between [Section A] and [Section B]?” or “Suggest thematic overlaps I’ve overlooked.”
Critique Generation: Ask for specific feedback, such as, “Critique the logical flow of this section” or “Analyze the character development in this chapter.”
5. Iterative Refinement
Analyze the outputs and iteratively refine the RAG system by adjusting the prompts, embeddings, or fine-tuning the model based on your unique style and goals.
```
* prompt
```txt
Is there an aider but for prose? What I'm looking for is something that has aider's map of everything you've written https://aider.chat/docs/repomap.html
+ text transform i.e. "take this paragraph and turn it into Proust"

https://www.hyperwriteai.com/aitools/text-style-transfer
```

---

https://github.com/hfhoffman1144/langchain_neo4j_rag_app https://realpython.com/build-llm-rag-chatbot-with-langchain/
⭐️ start here https://github.com/theam/rag-workshop-pydata-nyc-2024 https://www.youtube.com/watch?v=C4u1SjGiT_8 https://www.youtube.com/watch?v=XU2xhCHqILE

https://news.ycombinator.com/item?id=42360685
https://github.com/koaning
https://www.youtube.com/watch?v=kCCC-NlJgIA
https://simonwillison.net/2024/Dec/6/roaming-rag/
pipelines https://www.youtube.com/watch?v=YM3UrQd2wEA
* https://lincolnloop.com/insights/building-a-chat-backend-for-wikipedia-articles-in-django/
* BYO https://github.com/bhavnicksm/chonkie https://github.com/explosion/spacy-layout https://training.talkpython.fm/courses/getting-started-with-spacy https://github.com/DS4SD/docling https://x.com/_inesmontani
> I said earlier that building an LLM was still out of reach of hobbyists. That may be true for training from scratch, but fine-tuning one of those models is another matter entirely.  There’s now a fascinating ecosystem of people training their own models on top of these foundations, publishing those models, building fine-tuning datasets and sharing those too. The Hugging Face Open LLM Leaderboard is one place that tracks these. I can’t even attempt to count them, and any count would be out-of-date within a few hours. https://simonwillison.net/2023/Dec/31/ai-in-2023/ more on Hugging Face https://chatgpt.com/c/6750c201-f928-8004-b614-fb258458167a
* howto: Python in a sidecar and then your server in another language (that lacks Python's ML stdlib) talks to that https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/

START HERE 🗄️ `algos.md` neural networks
https://github.com/Shubhamsaboo/awesome-llm-apps https://www.theunwindai.com/p/build-a-personal-health-and-fitness-ai-agent-using-google-gemini
* https://www.youtube.com/watch?v=PJaqp5Kdwz0
* https://github.com/pingcap/autoflow https://github.com/stanfordnlp/dspy
* https://news.ycombinator.com/item?id=42174829
* https://haystack.deepset.ai/overview/quick-start https://www.youtube.com/watch?v=6aYclVrsqu0 https://www.youtube.com/watch?v=KYxlM0hh96o
* https://github.com/D-Star-AI/dsRAG/
* https://github.com/snexus/llm-search
* https://arcturus-labs.com/blog/2024/11/21/roaming-rag--make-_the-model_-find-the-answers/

* https://www.thoughtworks.com/radar/techniques/fine-tuning-embedding-models
* https://openai.com/12-days/
* _Guru_: https://www.getguru.com/
> Retrieval augmented generation (RAG) is an architecture that provides the most relevant and contextually-important proprietary, private or dynamic data to your Generative AI application's large language model (LLM) when it is performing tasks to enhance its accuracy and performance. https://www.pinecone.io/learn/retrieval-augmented-generation/
* BYO https://www.youtube.com/@zackproser/videos https://aws.amazon.com/bedrock/ https://simonwillison.net/2024/Dec/6/llama-33/
* _RAG_: document-based interactions https://github.com/sigoden/aichat#rag-chat-with-your-documents TTS https://changelog.com/practicalai/288 https://zackproser.com/blog/how-are-embeddings-models-trained-for-rag https://www.manning.com/books/a-simple-guide-to-retrieval-augmented-generation knowledge graph https://www.manning.com/books/knowledge-graph-enhanced-rag
* when you need more than either aaS or OSS
> If such a customized LLM is a suitable solution for your project, consider just running Ollama or Llamafile and using their REST APIs to communicate with the model. If you need higher degrees of customization, read on. https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/
* BYO https://us.pycon.org/2024/schedule/presentation/103/index.html https://github.com/Quansight/ragna
> We’re going to build a RAG server in Go. This is an HTTP server that provides two operations to users: Add a document to the knowledge base. Ask an LLM a question about this knowledge base. https://go.dev/blog/llmpowered
> You talked a lot about this distinction between LLM benchmarks and evaluating LLM applications. Could you talk a little bit about the differences? Maybe there are software engineers in the audience, that maybe they’re used to writing unit tests and integration tests for their software. Now as a consumer, as you said, they’re integrating some LLM functionality, or maybe a chain of reasoning with LLMs into their software. From a practical standpoint, what are the new types of things that they might need to consider that are different maybe from the way that they’ve unit-tested in the past, or written tests in the past, now that they’re working with these LLM workflows? https://changelog.com/practicalai/284#transcript
> Generative AI models struggle when you ask them about facts not covered in their training data. Retrieval Augmented Generation—or RAG—enhances an LLM’s available data by adding context from an external knowledge base, so it can answer accurately about proprietary content, recent information, and even live conversations. https://www.manning.com/books/a-simple-guide-to-retrieval-augmented-generation
> Claude's extensive context window has also transformed their approach to handling large codebases. When the 200K context window was released, Hedley notes they "ripped out the entire RAG and just put it in the context window instead and it went from 60 percent accuracy to 98. It was quicker, cheaper, better, everything." This combination of automation, speed, and accuracy has fundamentally changed how Headstart approaches software development. https://www.anthropic.com/customers/headstart
https://openai.com/index/introducing-canvas/
* https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/
https://zackproser.com/blog/i-am-joining-pinecone-io
* RAG, vector https://news.ycombinator.com/item?id=41105130 https://en.wikipedia.org/wiki/Retrieval-augmented_generation https://retool.com/blog/retrieval-augmented-generation https://www.youtube.com/watch?v=Q75JgLEXMsM https://www.youtube.com/watch?v=PJaqp5Kdwz0
* how to teach https://news.ycombinator.com/item?id=38759877
* with notes https://github.com/reorproject/reor
https://www.amazon.com/gp/product/1098107969
* _NotebookLM_: https://notebooklm.google.com/ https://simonw.substack.com/p/video-scraping-using-google-gemini
* https://simonw.substack.com/p/video-scraping-using-google-gemini
* tokens https://github.com/simonw/ttok
* AWS Textract https://github.com/simonw/textract-cli
* chat with your docs https://github.com/Cinnamon/kotaemon
* ingest all your notes https://news.ycombinator.com/item?id=41732634
* analyze research papers https://elicit.com/
* PDF https://dev.to/jagroop2001/building-a-chat-with-pdfs-using-pinataopenai-and-streamlit-3jb7
* https://www.assemblyai.com/

BYO
* https://www.youtube.com/watch?v=kCc8FmEb1nY
* https://news.ycombinator.com/item?id=41412256&utm_term=comment
* https://spreadsheets-are-all-you-need.ai/index.html
* https://iamjoshknox.com/2023/12/06/econeats-an-ai-dining-guide/
* https://www.saaspegasus.com/guides/django-websockets-chatgpt-channels-htmx
* https://github.com/langgenius/dify
* https://github.com/BerriAI/litellm

* _langchain_: https://zackproser.com/blog/office-oracle-overview https://www.amazon.com/dp/1835083463 https://x.com/aidenybai/status/1895218891586224488
* LangGraph https://realpython.com/langgraph-python/
> We mentioned some of the emerging criticisms about LangChain in the previous Radar. Since then, we’ve become even more wary of it. While the framework offers a powerful set of features for building applications with large language models (LLMs), we’ve found it to be hard to use and overcomplicated. LangChain gained early popularity and attention in the space, which turned it into a default for many developers. However, as LangChain is trying to evolve and keep up with the fast pace of change, it has become harder and harder to navigate those changes of concepts and patterns as a developer. We’ve also found the API design to be inconsistent and verbose. As such, it often obscures what is actually going on under the hood, making it hard for developers to understand and control how LLMs and the various patterns around them actually work. We’re moving LangChain to the Hold ring to reflect this. In many of our use cases, we’ve found that an implementation with minimum use of specialized frameworks is sufficient. Depending on your use case, you may also want to consider other frameworks such as Semantic Kernel, Haystack or LiteLLM.  https://www.thoughtworks.com/radar/languages-and-frameworks/langchain

# 🥗 MENU

💰 pricing https://www.llm-prices.com/ https://simonwillison.net/2025/Apr/10/llm-pricing-calculator/
* naming conventions https://www.dbreunig.com/2025/02/04/a-gentle-intro-to-running-a-local-llm.html
🛠️ benchmark https://arena.lmsys.org/
🔍 compare https://news.ycombinator.com/item?id=42348513 https://simonwillison.net/2024/Dec/16/webdev-arena/
🔑 https://gist.github.com/zachvalenta/d3b7cd172dd2d3d8ff7340bd458c6fe2

SLM
* _Gemini nano_: 
* _MS phi_:

ZA
* _BERT_: https://simonwillison.net/2024/Dec/31/alexis-gallagher/ https://github.com/urchade/GLiNER
* _DeepSeek_: https://thezvi.substack.com/p/deekseek-v3-the-six-million-dollar https://www.chinatalk.media/p/deepseeks-edge https://simonwillison.net/2024/Dec/31/llms-in-2024/#was-the-best-currently-available-llm-trained-in-china-for-less-than-6m-
* _X grok_: seems tied to Twitter https://grok.x.ai/ good now? https://simonwillison.net/2025/Feb/18/andrej-karpathy-grok-3/

---

OPEN https://simonwillison.net/2024/Jun/17/cli-language-models/
* _Codestral_: https://ollama.com/blog/continue-code-assistant
* _Centaur_: https://x.com/marcel_binz/status/1850806691958313160
* _Gemma_: https://ai.google.dev/gemma
* _jan_: 🎯 https://github.com/janhq/jan
* _Qwen_: https://simonw.substack.com/p/qwen25-coder-32b-is-an-llm-that-can

CLOSED
* _Amazon nova_: https://news.ycombinator.com/item?id=42309121 https://news.ycombinator.com/item?id=42309121 https://simonwillison.net/2024/Dec/4/amazon-nova/ https://simonwillison.net/2024/Dec/4/amazon-nova/
* backed by Amazon https://news.ycombinator.com/item?id=42215126
* _Mistral codestral_: less polished but fast + search https://chat.mistral.ai/chat
* Mixtral https://mistral.ai/news/mixtral-of-experts/
* YiCoder: https://news.ycombinator.com/item?id=41453237
* features: moderation, tuning to domain
* Haiku
* Genie https://news.ycombinator.com/item?id=42317903

## ☸️ ChatGPT

🔑 https://platform.openai.com/api-keys

MODELS
* legacy: 22.11 GPT 23.03 GPT4
* _4o_: 24.05
* _o1_: https://simonwillison.net/2024/Dec/7/prompts-js/ https://marginalrevolution.com/marginalrevolution/2024/12/dean-ball-speaks.html
* _o1 pro_: 24.12 (preview in 24.09) https://thezvi.substack.com/p/o1-turns-pro https://x.com/mckaywrigley/status/1865089975802646857 https://news.ycombinator.com/item?id=42330732
* _o3-mini_: deprecated https://simonwillison.net/2025/Apr/17/ted-sanders/
* _o4-mini_: good at vision https://simonwillison.net/2025/Apr/16/james-betker/
* _4.1_: https://openai.com/index/gpt-4-1/

ZA
* 1-800-CHATGPT https://help.openai.com/en/articles/10193193-1-800-chatgpt-calling-and-messaging-chatgpt-with-your-phone
* internal libraries, `ace_tools` https://community.openai.com/t/chatgpt-recommends-the-use-of-the-open-ai-internal-library-ace-tools/852665
* native client: global hotkey conflicts with iterm https://openai.com/chatgpt/mac
* ❌ started having uptime issues 24.12

WEB CLIENT
* search added 241031 (intra-doc but slow, none by title)
* projects added 241214
* when you open a chat it's not reflected in the sidebar so if you want to rename or delete it you have to scroll sidebar and manually find it
* ❌ no page up/down, no home/end
* dark mode is bad for seeing prompt

## 🟫 Claude

🔑 https://console.anthropic.com
📜 https://docs.anthropic.com/en/home
🔢 https://docs.anthropic.com/en/release-notes/overview

WEB CLIENT
* fast input 🗄️ `vim.md` Zed
* good font
* code syntax highlighting
* retry
* mass delete
* controls (artifacts = output, content = attachments)
* org: search/stars
* outputs code in a sidebar to prevent tons of scrolling in the main chat
* interop with Google Docs
* ✅ yes page up/down, yes home/end
* ❌ conventions: user-level and per project
> doesn't listen, continues to gen typed Python
> conversations bleed, starts giving me Click CLIs when I haven't asked for them
* ❌ projects: can't add chat to project after the fact, can't view chats as part of projects
* ❌ can't follow URLs

MODELS
> built on AWS https://simonwillison.net/2024/Dec/5/claude-35-haiku-price-drops-by-20/
* _Sonnet_: best for code https://simonwillison.net/2025/Jan/13/codestral-2501/
* _Haiku_: fastest, better than GPT 3.5 https://www.youtube.com/watch?v=QUXQNi6jQ30 [5:30]
* _Opus_: writing

---

CONTEXT
* system prompt https://docs.anthropic.com/en/docs/build-with-claude/prompt-engineering/system-prompts
* developer console https://www.anthropic.com/news/evaluate-prompts
* projects https://www.anthropic.com/news/projects how to get good at projects https://x.com/patrick_oshag/status/1876455619516911720

* allegedly the best but GPT legacy model beat it and the other time I tried it admitted to fabricating data https://x.com/emollick/status/1849168452914938082 https://simonwillison.net/2024/Oct/21/claude-artifacts/ https://darioamodei.com/

## 📚 Perplexity

* _Perplexity api_: search/org https://www.perplexity.ai/

## 🌉 Gemini

* no search/tags/org

---

* are the actual players https://news.ycombinator.com/item?id=43661235
* https://thezvi.substack.com/p/the-second-gemini
* voice https://news.ycombinator.com/item?id=42397210
* https://simonw.substack.com/p/video-scraping-using-google-gemini

## hardware

🗄️ `hw.md` Apple 
💻 https://github.com/zachvalenta/apple-models-data-analysis https://news.ycombinator.com/item?id=43268210

https://simonw.substack.com/p/qwen25-coder-32b-is-an-llm-that-can https://simonwillison.net/2024/Dec/9/llama-33-70b/ https://news.ycombinator.com/item?id=42539155&

> 🎗️ llamafile https://simonwillison.net/2024/Jun/17/cli-language-models/ https://simonwillison.net/2023/Nov/29/llamafile/ "this should be technically impossible" (having a single unmodified binary run across mac/Windows/linux) https://www.youtube.com/watch?v=QUXQNi6jQ30 [20:00]
* mini23 uses 8B just w/ VS Code + browser + macOS core services
* Qwen req 32B
* Simon has 64B

---

* https://www.docker.com/blog/introducing-docker-model-runner/
* https://simonwillison.net/2024/Dec/31/llms-in-2024/#apple-intelligence-is-bad-apple-s-mlx-library-is-excellent
* https://github.com/getumbrel/llama-gpt
* https://github.com/Mozilla-Ocho/llamafile
* llamafile https://news.ycombinator.com/item?id=40424519
* https://ollama.com/blog/how-to-prompt-code-llama https://ollama.com/blog/run-code-llama-locally

## 🦙 llama

* https://simonwillison.net/2025/Apr/20/janky-license/
* TUI https://github.com/paulrobello/parllama
* DeepSeek https://www.youtube.com/watch?v=dS9Vbye-xSY
* https://simonwillison.net/2025/Feb/7/pip-install-llm-smollm2/
* _Meta llama_: https://x.com/rowancheung/status/1865107700087980170 https://en.wikipedia.org/wiki/Llama_(language_model) uncensored https://ollama.com/blog/llama-3-is-not-very-censored https://ollama.com/blog/run-llama2-uncensored-locally https://joshuacook.netlify.app/posts/2024-01-31_ollama-quickstart/
* ccmake https://news.ycombinator.com/item?id=42274489
* _ollama_: ⭐️ https://ollama.com/
> customize through a Modelfile, incl model parameters, system prompts etc. https://eli.thegreenplace.net/2024/ml-in-go-with-a-python-sidecar/
* multimodal, OCR https://ollama.com/blog/llama3.2-vision https://www.youtube.com/watch?v=wTukMgtkleA LanceDB https://talkpython.fm/episodes/show/488/multimodal-data-with-lancedb

# 🏗️ OPERATIONALIZE

start here https://parlance-labs.com/education/ https://applied-llms.org/ https://www.agentrecipes.com/prompt-chaining

> The biggest problem: developers don’t want GPUs. They don’t even want AI/ML models. They want LLMs. System engineers may have smart, fussy opinions on how to get their models loaded with CUDA, and what the best GPU is. But software developers don’t care about any of that. When a software developer shipping an app comes looking for a way for their app to deliver prompts to an LLM, you can’t just give them a GPU. For those developers, who probably make up most of the market, it doesn’t seem plausible for an insurgent public cloud to compete with OpenAI and Anthropic. Their APIs are fast enough, and developers thinking about performance in terms of “tokens per second” aren’t counting milliseconds. https://fly.io/blog/wrong-about-gpu/

---

📙
* Clinton obsolete gen AI
* https://www.amazon.com/gp/product/1736049127
* https://www.amazon.com/dp/1736049143
* Brosseau LLMs in production https://www.manning.com/books/llms-in-production

* retrieval vs. generative https://cohere.com/
* testing https://news.ycombinator.com/item?id=42317878 https://news.ycombinator.com/item?id=42330666 https://github.com/BCG-X-Official/artkit https://www.youtube.com/watch?v=pGZo9gR5q_M https://gentrace.ai/ https://github.com/traceloop/openllmetry https://langfuse.com/ https://www.thoughtworks.com/radar/platforms/langfuse https://news.ycombinator.com/item?id=42441258 https://www.thoughtworks.com/radar/techniques/llm-as-a-judge

* gradient-boosted trees better for audit than neural nets
* https://roadmap.sh/mlops
* https://news.ycombinator.com/item?id=35438192
* https://applied-llms.org/
* https://news.ycombinator.com/item?id=38120493
* MLflow https://www.thoughtworks.com/radar/tools/mlflow metaflow https://www.thoughtworks.com/radar/tools?blipid=202203023
* can't debug like traditional programming [Ferguson 7]
* aka ml ops https://news.ycombinator.com/item?id=20865012 https://testdriven.io/blog/machine-learning-reliability-engineering/
* web app integration https://github.com/xadrianzetx/fullstack.ai https://news.ycombinator.com/item?id=20865012 https://talkpython.fm/episodes/transcript/226/building-flask-apis-for-data-scientists https://testdriven.io/blog/fastapi-machine-learning/
* quants can't code, coders can't quant https://news.ycombinator.com/item?id=23941075
* 90% of the job is munging data, models are implemented by people w/ PhDs https://towardsdatascience.com/the-cold-start-problem-how-to-build-your-machine-learning-portfolio-6718b4ae83e9 https://spectrum.ieee.org/view-from-the-valley/artificial-intelligence/machine-learning/andrew-ng-xrays-the-ai-hype more on job market https://evjang.com/2022/04/25/rome.html
* https://www.youtube.com/watch?v=JLTYNPoK7nw https://www.youtube.com/watch?v=pvaIi0l1GME https://softwareengineeringdaily.com/2019/06/13/stripe-machine-learning-infrastructure-with-rob-story-and-kelley-rivoire/
* this seems dumb but maybe I don't understand yet https://calmcode.io/course/deon/introduction

## Hugging Face

* run inside Postgres https://github.com/serpent7776/pg_sentence_transformer

> Transformers supports the majority of models available in Hugging Face’s Model Hub, and encompasses diverse tasks in natural language processing, computer vision, and audio processing...Because it’s built on top of PyTorch, TensorFlow, and JAX, [Hugging Face] `transformers` gives you the flexibility to use these frameworks to run and customize models at any stage. Using open-source models through Transformers has several advantages: Proprietary AI companies like OpenAI, Cohere, and Anthropic often charge you a token fee to use their models via an API. This means you pay for every token that goes in and out of the model, and your API costs can add up quickly. By deploying your own instance of a model with Transformers, you can significantly reduce your costs because you only pay for the infrastructure that hosts the model. https://realpython.com/huggingface-transformers/#exploring-hugging-face

ZERO-SHOT CLASSIFICATION
```python
model_name = "MoritzLaurer/deberta-v3-large-zeroshot-v2.0"
zs_text_classifier = pipeline(model=model_name)
candidate_labels = [
     "Billing Issues",
     "Technical Support",
     "Account Information",
     "General Inquiry",
]

hypothesis_template = "This text is about {}"

customer_text = "My account was charged twice for a single order."
zs_text_classifier(
    customer_text,
    candidate_labels,
    hypothesis_template=hypothesis_template,
    multi_label=True
)

"""
{'sequence': 'My account was charged twice for a single order.',
 'labels': ['Billing Issues',
            'General Inquiry',
            'Account Information',
            'Technical Support'],
 'scores': [0.98844587,
            0.01255007,
            0.00804191,
            0.00021988]}
"""
```
* image classification
```sh
python -m pip install Pillow
```
```python
image_classifier = pipeline(task="image-classification")
predictions = image_classifier(["llamas.png"])
predictions[0][0]  # {'label': 'llama', 'score': 0.9991388320922852}
predictions[0][1]  # {'label': 'Arabian camel, dromedary, Camelus dromedarius', 'score': 8.780974167166278e-05}
```


SENTIMENT ANALYSIS, TSS https://www.freecodecamp.org/news/get-started-with-hugging-face/
```sh
pip install transformers, tokenizers, datasets
```
```python
from transformers import pipeline

sentiment_analysis = pipeline("sentiment-analysis", model="distilbert-base-uncased-finetuned-sst-2-english")
input_text = [ "It’s a great app, my biggest problem is the card readers regularly do not connect. Which is very poor customer service for us because we have to manually enter our customers debit cards, which takes time. This slows down our efficiency." ]
result = sentiment_analysis(input_text)

transcriber = pipeline(task="automatic-speech-recognition", model="openai/whisper-small")
result = transcriber("https://huggingface.co/datasets/Narsil/asr_dummy/resolve/main/mlk.flac")
```

## evals

* https://simonwillison.net/2025/Apr/24/exploring-promptfoo/
* https://simonwillison.net/2025/Apr/18/andrew-ng/
* https://simonwillison.net/2025/Mar/8/nicar-llms/
* https://simonwillison.net/2025/Apr/1/pydantic-evals/
* https://platform.openai.com/docs/guides/evals
* https://simonwillison.net/2025/Apr/17/ted-sanders/

## keyword search

https://www.youtube.com/watch?v=d5i5Lc9X4Og
> 122 views 3 weeks after upload! what are people doing with their time!

> Keyword search is the traditional approach where the search engine looks for exact matches or close variants of the words in the query. For example, if you search "red car," it finds documents containing those exact words. It's fast and straightforward but can miss relevant results that use different terminology (like "crimson automobile").

## hybrid search

> Hybrid search combines both approaches to leverage their respective strengths. It typically uses keyword search for precise matches and high-confidence results, while incorporating semantic search to catch relevant results that wouldn't be found through exact word matching alone. For instance, an e-commerce site might use keyword search to find products with exact name matches, while using semantic search to suggest related items that might interest the user even if they don't contain the exact search terms.

> A practical example: If you search "how to treat a headache," a hybrid system would:
> Use keyword matching to find articles containing "headache" and "treat"
> Use semantic search to also find relevant content about "migraine remedies" or "pain relief techniques"
> Combine and rank these results based on both literal relevance and semantic meaning

## semantic search

🗄️ `ml.md` vectors

BYO + RAG https://claude.ai/chat/ec4dbe09-e48a-466f-9e35-a7e430af0265
https://www.inotherwords.app/linguabase/

---

https://www.inotherwords.app/linguabase/
https://koratkar.github.io/cwt-semantic-search/

> Semantic search understands the meaning and intent behind queries rather than just matching words. It uses techniques like word embeddings and neural networks to understand context and relationships. For example, a semantic search for "red car" might also return results about "scarlet vehicles" or even "burgundy SUVs" because it understands these are conceptually related. It's particularly good at handling natural language queries and understanding synonyms, but can be more computationally intensive.

* https://amjith.com/blog/2023/vector_search/
* https://koratkar.github.io/cwt-semantic-search/ https://x.com/whybyfire/status/1866239929732173846
> So semantic search is often a component of RAG, but RAG goes beyond just search. Here's an analogy: semantic search is like having a really smart librarian who understands what you're looking for and can find relevant books. RAG is like having that librarian plus a subject matter expert who can read those books, synthesize the information, and explain it to you in your own terms. https://claude.ai/chat/18bc4333-ff09-45f8-8610-0c325ce11ecf

https://chatgpt.com/c/675b9317-4bc4-8004-a0a5-b9d683ebd3d8 (now deleted)
> Semantic search is a search methodology that focuses on understanding the intent and contextual meaning of a query, rather than just matching keywords. It uses techniques like: Word embeddings to encode text meaning. Vector similarity to find relevant matches in a corpus. Contextual models, often based on transformers like BERT or Sentence-BERT, to retrieve results based on semantic relevance. Semantic search is focused on retrieval, aiming to return the most relevant documents, snippets, or knowledge units in response to a query.
> RAG is a hybrid system that combines two key stages: Retrieval: Uses semantic search or similar retrieval mechanisms to fetch relevant documents or knowledge pieces in response to a query. Generation: Uses a generative model (e.g., GPT or another transformer) to produce a response. The model conditions its output on both the query and the retrieved content.

https://news.ycombinator.com/item?id=42507116

## train

📙
* Brosseau LLMs in production https://www.manning.com/books/llms-in-production
* Labonne https://github.com/PacktPublishing/LLM-Engineers-Handbook https://www.amazon.com/gp/product/1836200072
🧠 https://chatgpt.com/c/6756f73a-9d68-8004-9ef8-34d9744f767d

* _train_: further training pretrained model on specific domains using labeled data or prompts 📙 Clinton obsolete gen AI

---

* https://x.com/thegautam/status/1920198569308664169
* https://realpython.com/huggingface-transformers/#looking-under-the-hood-with-auto-classes
* https://realpython.com/huggingface-transformers/#setting-up-a-google-colab-notebook
* Fine-tuning (Full or Transfer Learning)
> Requires substantial compute and a large, high-quality dataset
* Parameter-Efficient Fine-Tuning (LoRA / PEFT)   
* Reinforcement Learning (RLHF or Task-Specific)

* train on your own emails https://github.com/zycyc/LAMBDA
data prep kit https://www.youtube.com/watch?v=tqRvmg2F_gI https://github.com/IBM/data-prep-kit
> assume we'd use transfer or reinforcement learning vs. getting into the weeds with adjusting the weights (finetuning, LoRA, PEFT)

https://changelog.com/practicalai/295

* inference scaling vs. model scaling https://simonwillison.net/2024/Dec/19/is-ai-progress-slowing-down/

# 🏗️ USAGE

🔍 https://a16z.com/100-gen-ai-apps-3/

---

writing https://www.sudowrite.com/
usage aka modality e.g. GPT understanding images with GPT4 examples of multimodality i.e. text and images

ZA
* text to SQL https://github.com/vanna-ai/vanna
* to synthesize all comments on a product into a blurb https://blog.untrod.com/2024/04/llm-chatgpt-powered-django-admin-fields.html
* copyedit a novel https://blog.untrod.com/2023/06/copy-editing-a-novel-with-chatgpt.html
* detection https://deepmind.google/technologies/synthid/?utm_source=www.superpowerdaily.com&utm_medium=newsletter&utm_campaign=new-claude-ai-can-take-over-your-computer

https://platform.openai.com/docs/overview https://cookbook.openai.com/

## audio

🗄️ Hugging Face

GPT has a STT endpoint 📙 Clinton

TYPES https://elevenlabs.io/
* didn't work https://huggingface.co/spaces/openai/whisper https://goodsnooze.gumroad.com/l/macwhisper https://news.ycombinator.com/item?id=42095294
* dubbing
* voice clone https://www.tetragrammaton.com/content/richard-feynman
* _TTS_: https://www.openai.fm/ https://notebooklm.google/ https://news.ycombinator.com/item?id=41964980 PDF to audio https://www.fwdaudio.com/ https://x.com/barbell_fi multistage https://simonw.substack.com/p/verdad-tracking-misinformation-in https://www.fwdaudio.com/ https://news.ycombinator.com/item?id=43022398
> Everyone is talking about the new hashtag#AI Notebook LM tool from Google that lets you create podcasts from articles and other sources. I decided to try it for myself, using one of my prior pieces, The Upside and Downside of AI, as the basis for the podcast. The result, which you can listen to in the article, is simply amazing. It doesn't just read the article - it has a discussion between two "people" about it that is very engaging. https://arnoldkling.substack.com/p/llm-links-b9d
> Meta recently introduced NotebookLlama, an "open" version of Google’s podcast-generating feature found in NotebookLM. Leveraging Meta's Llama models, NotebookLlama is capable of creating conversational, podcast-style digests of uploaded text files, such as PDFs of news articles or blog posts. This technology aims to replicate the interactive storytelling aspect of Google's viral tool, adding its own elements of dramatization and interruptions to make the content sound more dynamic. https://www.superpowerdaily.com/p/google-preps-jarvis-ai-agent-that-works-in-chrome
* _STT_: https://news.ycombinator.com/item?id=41941845 https://www.scattered-thoughts.net/writing/hytradboi-2025-postmortem/

---

* TTS https://github.com/fishaudio/fish-speech https://til.simonwillison.net/ios/listen-to-page Hugging Face https://til.simonwillison.net/macos/whisper-cpp
* text to voice e.g. AWS Polly https://aws.amazon.com/blogs/aws/introducing-aws-b2b-data-interchange-simplified-connections-with-your-trading-partners/
* transcription https://news.ycombinator.com/item?id=41199567 https://www.theguardian.com/media/2014/jan/22/ten-tools-for-digital-and-citizen-journalists-on-the-go
* audio prompt + voice cloning for answer https://blog.untrod.com/2023/11/robot-dad.html https://elevenlabs.io/
* voice clone https://www.jeffgeerling.com/blog/2024/elecrow-responded-apologized-ai-voice-cloning
* speech to text https://github.com/kyutai-labs/moshi
* generative music https://www.garbageday.email/p/suno-just-raised-lot-money
* vocals https://audimee.com/
* Siri https://github.com/homebrewltd/ichigo
* mastering https://www.youtube.com/watch?v=wZRV2H4PK0Q
* tone https://x.com/ilanbigio/status/1861913173432946808

## forecasting

https://arxiv.org/pdf/2411.01582
> use to build stock market

## img

EXAMPLES
* https://www.mercatus.org/doge

* _TTV_: https://simonwillison.net/2024/Dec/9/sora/
* _TFI_: https://calmcode.io/shorts/pytesseract.py
* image to video https://www.vidifyapp.com/
* _OCR_: image to text e.g. PDF to plaintext https://en.wikipedia.org/wiki/Optical_character_recognition https://news.ycombinator.com/item?id=41048194 https://getomni.ai/ocr-demo https://news.ycombinator.com/item?id=41971614 https://github.com/Nutlope/llama-ocr https://simonwillison.net/2025/Feb/26/olmocr/  https://mistral.ai/fr/news/mistral-ocr

---

* https://simonwillison.net/2025/May/5/llm-video-frames/
* video https://x.com/bilawalsidhu/status/1857816146688217099
* video scraping https://simonw.substack.com/p/video-scraping-using-google-gemini
* image recognition https://www.youtube.com/watch?v=XPA213k8G_U
* image to spreadsheet https://news.ycombinator.com/item?id=41059821 https://en.wikipedia.org/wiki/IFTTT
* deep fakes https://github.com/hacksider/Deep-Live-Cam
* image search https://tembo.io/blog/image-search
* https://github.com/GabAlpha/basilk https://perchance.org/ai-pixel-art-generator
* Midjourney https://midlibrary.io/styles
* DALL-E
* Stable Diffusion https://www.youtube.com/watch?v=kG9l41Dtuyo
* https://news.ycombinator.com/item?id=40437641
* https://github.com/orhun/menyoki

## projects

* character relationships https://news.ycombinator.com/item?id=43633298
* algos https://github.com/ritchie46/vanilla-machine-learning https://www.manning.com/books/optimization-algorithms
* get familiar https://simonwillison.net/2024/Apr/17/ai-for-data-journalism/
* https://www.freecodecamp.org/news/customer-segmentation-python-machine-learning/
* https://archive.vn/073bS
* https://news.ycombinator.com/item?id=40877136
* train model on dickens, cowen
* https://www.freecodecamp.org/learn/machine-learning-with-python/machine-learning-with-python-projects/book-recommendation-engine-using-knn
